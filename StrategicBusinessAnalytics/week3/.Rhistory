hist(inputRandomVariableU1000, breaks=40, xlab="Usage, U (in GB)", main="Distribution of Data Usage, U (in GB)", col="lightgreen", xlim=c(5,38),  ylim=c(0, 500))
hist(inputRandomVariableU1000, breaks=40, xlab="Usage, U (in GB)", main="Distribution of Data Usage, U (in GB)", col="lightgreen", xlim=c(5,38),  ylim=c(0, 100))
hist(inputRandomVariableU1000,
breaks=40,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
curve(dnorm(x,
mean=mean(inputRandomVariableU1000),
sd=sd(inputRandomVariableU1000)),
add=TRUE,
col="darkblue",
lwd=2)
hist(inputRandomVariableU1000,
breaks=40,
freq=FALSE,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
curve(dnorm(x,
mean=mean(inputRandomVariableU1000),
sd=sd(inputRandomVariableU1000)),
add=TRUE,
col="darkblue",
lwd=2)
hist(inputRandomVariableU1000,
freq=FALSE,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
hist(inputRandomVariableU1000,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
breaks=40,
hist(inputRandomVariableU1000,
breaks=40,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
curve(dnorm(x,
mean=mean(inputRandomVariableU1000),
sd=sd(inputRandomVariableU1000)),
add=TRUE,
col="darkblue",
lwd=2)
dataAllowance = 20
fixedPayment = 160
rateAboveAllowance = 15
expectedDataUsage = 23
stDevDataUsage = 5
inputRandomVariableU1000 = rnorm(1000, expectedDataUsage, stDevDataUsage)
histinfo<-hist(inputRandomVariableU1000)
histinfo
mean(inputRandomVariableU1000)
sd(inputRandomVariableU1000)
min(inputRandomVariableU1000)
max(inputRandomVariableU1000)
hist(inputRandomVariableU1000, breaks=40)
hist(inputRandomVariableU1000,
breaks=40,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
onputRandomVariableP1000 = 160 + ifelse(inputRandomVariableU1000 > 20, 15 * (inputRandomVariableU1000 - 20), 0)
ouputRandomVariableP1000 = 160 + ifelse(inputRandomVariableU1000 > 20, 15 * (inputRandomVariableU1000 - 20), 0)
histinfo<-hist(ouputRandomVariableP1000)
histinfo
mean(ouputRandomVariableP1000)
sd(ouputRandomVariableP1000)
mean(ouputRandomVariableP1000)
sd(ouputRandomVariableP1000)
min(ouputRandomVariableP1000)
max(ouputRandomVariableP1000)
min(ouputRandomVariableP1000)
max(ouputRandomVariableP1000)
hist(ouputRandomVariableP1000,
breaks=40,
xlab="Payment, P (in $)",
main="Distribution of Payment, P (in $)",
col="blue",
xlim=c(160,450),
ylim=c(0, 500))
hist(ouputRandomVariableP1000,
breaks=40,
xlab="Payment, P (in $)",
main="Distribution of Payment, P (in $)",
col="blue",
xlim=c(160,450),
ylim=c(0, 400))
dataAllowance = 20
fixedPayment = 160
rateAboveAllowance = 15
# Data statistics
expectedDataUsage = 23
stDevDataUsage = 5
# set seed
set.seed(123)
# sample data & sample statistics
inputRandomVariableU1000 = rnorm(1000, expectedDataUsage, stDevDataUsage)
histinfo<-hist(inputRandomVariableU1000)
histinfo
mean(inputRandomVariableU1000)
sd(inputRandomVariableU1000)
min(inputRandomVariableU1000)
max(inputRandomVariableU1000)
# hitogram of sample data usage
hist(inputRandomVariableU1000,
breaks=40,
xlab="Usage, U (in GB)",
main="Distribution of Data Usage, U (in GB)",
col="lightgreen",
xlim=c(5,38),
ylim=c(0, 100))
# sample payment data and statistics
ouputRandomVariableP1000 = 160 + ifelse(inputRandomVariableU1000 > 20, 15 * (inputRandomVariableU1000 - 20), 0)
histinfo<-hist(ouputRandomVariableP1000)
histinfo
mean(ouputRandomVariableP1000)
sd(ouputRandomVariableP1000)
min(ouputRandomVariableP1000)
max(ouputRandomVariableP1000)
# hitogram of sample payment
hist(ouputRandomVariableP1000,
breaks=40,
xlab="Payment, P (in $)",
main="Distribution of Payment, P (in $)",
col="blue",
xlim=c(160,450),
ylim=c(0, 400))
rm(list=ls(all=TRUE))
rm(list=ls(all=TRUE))
# Let's load our dataset and call it data
data=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE) # The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
setwd("~/BDA/BusinessAnalytics/ESSEC/StrategicBusinessAnalytics/week2")
rm(list=ls(all=TRUE))
# Let's load our dataset and call it data
data=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE) # The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
hist(data$Rating) # Produce a histogram of the credit scores
cor(data[,c(1:5,10)]) # Compute the correlation between all the numerical variables of the sample
linreg=lm(Rating~.,data=data) # Estimate a linear regression model of Rating as a function of everything else.
#linreg=lm(Rating~Income+Cards+Married,data=data)
cor(linreg$fitted.values,data$Rating) # Computes the correlation between the fitted values and the actual ones
plot(data$Rating,linreg$fitted.values) # Plot the fitted values vs. the actual ones
summary(linreg) # Reports the results of the regression
plot(data$Balance,data$Rating) # Allows to visualize the relationship between Balance and Rating
plot(data$Income,data$Rating) # Allows to visualize the relationship between Income and Rating
# An aggregated plot: Education
tempdata=data
aggbTimeRank=aggregate(Rating~ Education, data=tempdata, FUN=mean) # We compute the average attrition rate for each value of TIC
plot(aggbTimeRank$Education,aggbTimeRank$left,main= "Credit Rating", ylab="Rating", xlab= "# education")
# An aggregated plot: Gender
tempdata=data
aggbTimeRank=aggregate(Rating~ Gender, data=tempdata, FUN=mean) # We compute the average attrition rate for each value of TIC
plot(aggbTimeRank$Gender,aggbTimeRank$left,main= "Credit Rating", ylab="Rating", xlab= "# education")
# An aggregated plot: Gender
tempdata=data
aggbTimeRank=aggregate(Rating~ Student, data=tempdata, FUN=mean) # We compute the average attrition rate for each value of TIC
plot(aggbTimeRank$Student,aggbTimeRank$left,main= "Credit Rating", ylab="Rating", xlab= "# education")
############################################################
####        EXAMPLE NÂ°2 - HR ANALYTICS 2                ####
############################################################
# Set your directory to the folder where you have downloaded the HR Analytics 2 dataset
# To clean up the memory of your current R session run the following line
rm(list=ls(all=TRUE))
# Let's load our dataset and call it datatot
datatot=read.table('DATA_3.02_HR2.csv', header = T,sep=',')
# Now let's have a look at our variables and see some summary statistics
str(datatot) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datatot) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
table(datatot$left) # look at the frequencies for the left variable
table(datatot$left)/nrow(datatot) # look at percentages for the left variable
hist(datatot$left) # alternatively, plot a histogram
cor(datatot) # Let's check out the correlations
logreg = glm(left ~ ., family=binomial(logit), data=datatot) # Estimate the drivers of attrition
hist(logreg$fitted.values) # See the proportion of employee attrition according to the model
cor(logreg$fitted.values,datatot$left) # Assess the correlation between estimated attrition and actual
cutoff=.5 # Cutoff to determine when P[leaving] should be considered as a leaver or not. Note you can play with it...
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0) # Compute the percentage of correctly classified employees who stayed
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1) # Compute the percentage of correctly classified employees who left
mean((logreg$fitted.values>cutoff)==(datatot$left==1)) # Compute the overall percentage of correctly classified employees
sum((logreg$fitted.values<=cutoff))
summary(logreg) # Report the results of the logistic regression
# Let's use a more visual way to see the effect of one of the most important driver: TIC
plot(datatot$TIC,datatot$left,main= "Time and Employee Attrition", ylab="Attrition", xlab= "Time spent")
# An aggregated plot
tempdata=datatot
aggbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=mean) # We compute the average attrition rate for each value of TIC
plot(aggbTimeRank$TIC,aggbTimeRank$left,main= "Time and Employee Attrition", ylab="Average Attrition Rate", xlab= "Time spent")
# An even better one!
cntbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=length) # We compute the number of employees for each value of TIC
symbols(aggbTimeRank$TIC,aggbTimeRank$left,circles=cntbTimeRank$left, inches=.75, fg="white", bg="red",main= "Time and Employee Attrition", ylab="Average Attrition Rate", xlab= "Time spent") # we
# Let's use a more visual way to see the effect of the most important driver: Satisfaction
tempdata=datatot
tempdata$rankSatis = round(rank(-tempdata$S)/600) # We create categories of employee satisfaction ranking. We create 20 groups (because it will work well later...)
aggbSatisRank = aggregate(left~ rankSatis, data=tempdata, FUN=mean) # We compute the average attrition rate for each category
cntbSatisRank = aggregate(left~ rankSatis, data=tempdata, FUN=length) # We compute the number of employees for each value of TIC
symbols(aggbSatisRank$rankSatis,aggbSatisRank$left,circles=cntbSatisRank$left, inches=.2, fg="white", bg="red",main= "Satisfaction and Employee Attrition", ylab="Average Attrition Rate", xlab= "Rank of Satisfaction")
setwd("~/BDA/BusinessAnalytics/ESSEC/StrategicBusinessAnalytics/week3")
rm(list=ls(all=TRUE))
rm(list=ls(all=TRUE))
# Let's load our dataset and call it data
dataold=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE) # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.01_CREDIT2.csv',sep=',',header=TRUE) # The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linreg=lm(Rating~.,data=dataold) # Estimate a linear regression model of Rating as a function of everything else.
predcreditscore = predict(linreg,newdata=datanew,type="response")
predcreditscore
cor(linreg$fitted.values,dataold$Rating) # Computes the correlation between the fitted values and the actual ones
plot(dataold$Rating,linreg$fitted.values) # Plot the fitted values vs. the actual ones
cor(predcreditscore,datanew$Rating) # Computes the correlation between the fitted values and the actual ones
plot(datanew$Rating,predcreditscore) # Plot the fitted values vs. the actual ones
rm(list=ls(all=TRUE))
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
probaToLeave
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
View(predattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
install.packages("survival") # Install the survival package to your computer
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
summary(survreg)  # The summary() function shows the output of your model
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5) # Make predictions based on the model. Here we estimate the median lifetime as the expected moment of "death"
Forecast=data.frame(Ebreak) # Create a dataframe to store the ouput of Ebreak
Forecast$lifetime=data$lifetime  # Add a column in the Forecast dataframe indicating the lifetime of the piece
View(Forecast)
Forecast
Forecast$broken=data$broken # Add a column in the Forecast dataframe indicating whether or not the piece is broken
View(Forecast)
View(data)
Forecast$RemainingLT=Forecast$Ebreak-data$lifetime # Computed Expected Remaining Lifetime
View(Forecast)
View(Forecast) # View the complete Forecast dataframe
Forecast=Forecast[order(Forecast$RemainingLT),] # Order the elements by Expected Remaining Lifetime
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
rm(list=ls())
# Let's load our dataset and call it data
data=read.table('DATA_4.04_CHOC.csv',sep=',',header=TRUE) # The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data$sales) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
plot(data$time,data$sales,main="Chocolate sales over time",xlab="Time (in month)",ylab="Monthly sales",ylim=c(0,max(data$sales*1.2)),type='l')
regres=lm(sales~month,data=data) # Build a linear regression model
summary(regres)
# Boxplots:
plot(data$month,data$sales,main="Chocolate sales by month",xlab="Month",ylab="Monthly sales",ylim=c(0,max(data$sales*1.2)))
# Recovery thanks to the model:
plot(data$time,data$sales,main="Chocolate sales over time",xlab="Time (in month)",ylab="Monthly sales",ylim=c(0,max(data$sales)*1.2),type='l')
lines(data$time,regres$fitted.values,type='l',col='blue',lty=2)
legend("topleft",c("Actual sales","Sales by the model"),lty=c(1,2),col=c('black','blue'))
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = FALSE),]
View(orderpredattrition)
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
orderpredattrition=predattrition[order(predattrition$probaToLeave,decreasing = FALSE),]
View(predattrition) # View the predattrition dataframe
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
orderpredattrition=predattrition[order(predattrition$probaToLeave,decreasing = FALSE),]
View(orderpredattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
orderpredattrition=predattrition[order(predattrition$probaToLeave,decreasing = FALSE),]
View(orderpredattrition)
View(orderpredattrition)
orderpredattrition[orderpredattrition$performance>.90,]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),].take(1)
min(which(orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),])
)
min(which(orderpredattrition$performance>.90))
min(which(order(orderpredattrition$performance>.90,decreasing = TRUE))
)
min(which(orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]))
min(which(orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]))
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),][0]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),][0]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderprobToLeavewithGreatPerformance=orderpredattritionorderpredattrition[order(orderprobToLeave$performance>.90,decreasing = TRUE),]
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
orderpredattrition=predattrition[order(predattrition$probaToLeave,decreasing = FALSE),]
View(orderpredattrition)
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
summary(survreg)  # The summary() function shows the output of your model
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
# survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Question 4
summary(survreg)  # The summary() function shows the output of your model
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
#survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Question 4
summary(survreg)  # The summary() function shows the output of your model
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5) # Make predictions based on the model. Here we estimate the median lifetime as the expected moment of "death"
Forecast=data.frame(Ebreak) # Create a dataframe to store the ouput of Ebreak
Forecast$lifetime=data$lifetime  # Add a column in the Forecast dataframe indicating the lifetime of the piece
Forecast$broken=data$broken # Add a column in the Forecast dataframe indicating whether or not the piece is broken
Forecast$RemainingLT=Forecast$Ebreak-data$lifetime # Computed Expected Remaining Lifetime
View(Forecast) # View the complete Forecast dataframe
Forecast=Forecast[order(Forecast$RemainingLT, decreasing = FALSE),] # Order the elements by Expected Remaining Lifetime
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
Forecast=Forecast[order(Forecast$RemainingLT, decreasing = TRUE),] # Order the elements by Expected Remaining Lifetime
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
Forecast=Forecast[order(Forecast$RemainingLT),] # Order the elements by Expected Remaining Lifetime
ActionsPriority=Forecast[Forecast$broken==0,] # And keep only those who are not broken yet
View(ActionsPriority) # View the output and take actions!
ForecastQ5=Forecast[order(Forecast$RemainingLT, decreasing = TRUE),]
ActionsPriorityQ5=ForecastQ5[ForecastQ5$broken==0,] # And keep only those who are not broken yet
View(ActionsPriorityQ5) # View the output and take actions!
rm(list=ls(all=TRUE))
# Let's load our dataset
dataold=read.table('DATA_3.02_HR2.csv', header = T,sep=',') # The function read.table enables us to read flat files such as .csv files
datanew=read.table('DATA_4.02_HR3.csv', header = T,sep=',') # The new dataset on which we want to make the prediction
str(datanew) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(datanew) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
logreg = glm(left ~ ., family=binomial(logit), data=dataold) # Estimate the drivers of attrition
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
probaToLeave
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
orderprobaToLeave=probaToLeave[order(probaToLeave$probaToLeave,decreasing = FALSE),]
orderprobaToLeave=probaToLeave[order(probaToLeave,decreasing = FALSE),]
probaToLeave=predict(logreg,newdata=datanew,type="response") # Make predictions on the out-of-sample data
predattrition = data.frame(probaToLeave) # Structure the prediction output in a table
View(predattrition) # View the predattrition dataframe
predattrition$performance=datanew$LPE # Add a column to the predattrition dataframe containing the performance
View(predattrition) # View the predattrition dataframe
plot(predattrition$probaToLeave,predattrition$performance)
predattrition$priority=predattrition$performance*predattrition$probaToLeave
View(predattrition)
orderpredattrition=predattrition[order(predattrition$priority,decreasing = TRUE),]
View(orderpredattrition)
# Question 1
orderpredattrition=predattrition[order(predattrition$probaToLeave,decreasing = FALSE),]
View(orderpredattrition)
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),][[0]]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
orderpredattrition[orderpredattrition$performance,]
orderpredattrition[orderpredattrition$probaToLeave,]
orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),]
View(orderpredattrition[order(orderpredattrition$performance>.90,decreasing = TRUE),])
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
#survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Question 4
summary(survreg)  # The summary() function shows the output of your model
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
install.packages("survival") # Install the survival package to your computer
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Question 4
summary(survreg)  # The summary() function shows the output of your model
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_4.03_MNT.csv',sep=',',header=TRUE)
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
linregmodel = lm(lifetime~.-broken,data=data)  # Build a linear regression model
summary(linregmodel) # The summary() function shows the output of your model
library(survival) # Load the survival package
dependantvars = Surv(data$lifetime, data$broken) # choose the dependant variables to be used in the survival regression model with the Surv() function
survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd+team+provider, dist="gaussian",data=data) # Create your survival regression model
#survreg = survreg(dependantvars~pressureInd+moistureInd+temperatureInd, dist="gaussian",data=data) # Question 4
summary(survreg)  # The summary() function shows the output of your model
Ebreak=predict(survreg, newdata=data, type="quantile", p=.5) # Make predictions based on the model. Here we estimate the median lifetime as the expected moment of "death"
Forecast=data.frame(Ebreak) # Create a dataframe to store the ouput of Ebreak
Forecast$lifetime=data$lifetime  # Add a column in the Forecast dataframe indicating the lifetime of the piece
Forecast$broken=data$broken # Add a column in the Forecast dataframe indicating whether or not the piece is broken
Forecast$RemainingLT=Forecast$Ebreak-data$lifetime # Computed Expected Remaining Lifetime
View(Forecast) # View the complete Forecast dataframe
ForecastQ5=Forecast[order(Forecast$RemainingLT, decreasing = TRUE),]
ActionsPriorityQ5=ForecastQ5[ForecastQ5$broken==0,] # And keep only those who are not broken yet
View(ActionsPriorityQ5) # View the output and take actions!
